name: Deploy to Kubernetes

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        type: choice
        options:
          - deploy
          - undeploy
        default: 'deploy'
  # Automatic triggers disabled by default for security
  # Uncomment below to enable automatic runs on push
  # push:
  #   branches:
  #     - main
  #   paths:
  #     - 'k8s/**'
  #     - '.github/workflows/deploy-k8s.yml'

env:
  GOOGLE_CREDENTIALS: ${{ secrets.GCP_SA_KEY }}
  GOOGLE_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
  GOOGLE_REGION: ${{ secrets.GCP_REGION || 'us-central1' }}
  GOOGLE_ZONE: ${{ secrets.GCP_ZONE || 'us-central1-a' }}
  CLUSTER_NAME: ${{ secrets.GKE_CLUSTER_NAME || 'trt-llm-cluster' }}

jobs:
  deploy:
    name: Deploy to Kubernetes
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy'
    environment:
      name: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install gke-gcloud-auth-plugin
        run: |
          echo "[$(date)] Installing gke-gcloud-auth-plugin..."
          gcloud components install gke-gcloud-auth-plugin --quiet || {
            echo "[$(date)] Component install failed, trying alternative method..."
            # Alternative: Download and install manually
            ARCH=$(uname -m)
            if [ "$ARCH" = "x86_64" ]; then
              ARCH="amd64"
            elif [ "$ARCH" = "aarch64" ]; then
              ARCH="arm64"
            fi
            PLUGIN_VERSION=$(gcloud version --format="value(Google Cloud SDK)" | cut -d' ' -f4)
            curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-${PLUGIN_VERSION}-linux-${ARCH}.tar.gz 2>/dev/null || \
            curl -O https://storage.googleapis.com/cloud-sdk-release/google-cloud-cli-${PLUGIN_VERSION}-linux-${ARCH}.tar.gz 2>/dev/null || \
            echo "âš  Could not download plugin, will try to use gcloud auth"
          }
          # Ensure plugin is in PATH
          export USE_GKE_GCLOUD_AUTH_PLUGIN=True
          echo "[$(date)] gke-gcloud-auth-plugin installation attempted"

      - name: Configure kubectl
        env:
          USE_GKE_GCLOUD_AUTH_PLUGIN: True
        run: |
          echo "[$(date)] Configuring kubectl for GKE cluster..."
          gcloud container clusters get-credentials \
            ${{ env.CLUSTER_NAME }} \
            --zone ${{ env.GOOGLE_ZONE }} \
            --project ${{ secrets.GCP_PROJECT_ID }}
          echo "[$(date)] kubectl configured successfully"

      - name: Install Helm
        run: |
          echo "[$(date)] Installing Helm..."
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version
          echo "[$(date)] Helm installed"

      - name: Install jq
        run: |
          echo "[$(date)] Installing jq..."
          sudo apt-get update && sudo apt-get install -y jq
          echo "[$(date)] jq installed"

      - name: Verify GPU support
        run: |
          echo "[$(date)] Verifying GPU support in cluster..."
          kubectl get nodes -o json | jq -r '.items[] | select(.status.allocatable."nvidia.com/gpu" != null) | "âœ“ \(.metadata.name): \(.status.allocatable."nvidia.com/gpu") GPU(s)"' || echo "âš  No GPU nodes found"
          echo "[$(date)] GPU verification completed"

      - name: Clean up conflicting resources
        run: |
          echo "[$(date)] Checking for existing resources that might conflict..."
          # Delete existing LimitRange if it exists (to avoid duplicate type error)
          if kubectl get limitrange triton-inference-limits -n triton-inference 2>/dev/null; then
            echo "[$(date)] Removing existing LimitRange to avoid conflicts..."
            kubectl delete limitrange triton-inference-limits -n triton-inference --ignore-not-found=true
            sleep 2
          fi
          # Delete existing ResourceQuota if it exists
          if kubectl get resourcequota triton-inference-quota -n triton-inference 2>/dev/null; then
            echo "[$(date)] Removing existing ResourceQuota to avoid conflicts..."
            kubectl delete resourcequota triton-inference-quota -n triton-inference --ignore-not-found=true
            sleep 2
          fi
          echo "[$(date)] Cleanup completed"

      - name: Deploy with Helm
        run: |
          echo "[$(date)] Deploying with Helm..."
          # Check if namespace exists, if so, don't use --create-namespace
          if kubectl get namespace triton-inference 2>/dev/null; then
            echo "[$(date)] Namespace triton-inference already exists, skipping creation"
            # First, ensure PVCs exist or are created
            echo "[$(date)] Ensuring PVCs are created..."
            helm upgrade --install qwen3-8b-triton ./helm/qwen3-8b-triton \
              --namespace triton-inference \
              --timeout 10m \
              --set triton.enabled=true \
              --set openwebui.enabled=true \
              --set prometheus.enabled=true \
              --set namespace.create=false \
              --wait=false || {
              echo "âš  First install attempt had issues, trying with --force flag..."
              helm upgrade --install qwen3-8b-triton ./helm/qwen3-8b-triton \
                --namespace triton-inference \
                --timeout 10m \
                --set triton.enabled=true \
                --set openwebui.enabled=true \
                --set prometheus.enabled=true \
                --set namespace.create=false \
                --force \
                --wait=false
            }
          else
            echo "[$(date)] Creating namespace triton-inference"
            helm upgrade --install qwen3-8b-triton ./helm/qwen3-8b-triton \
              --namespace triton-inference \
              --create-namespace \
              --timeout 10m \
              --set triton.enabled=true \
              --set openwebui.enabled=true \
              --set prometheus.enabled=true \
              --wait=false || {
              echo "âš  First install attempt had issues, trying with --force flag..."
              helm upgrade --install qwen3-8b-triton ./helm/qwen3-8b-triton \
                --namespace triton-inference \
                --create-namespace \
                --timeout 10m \
                --set triton.enabled=true \
                --set openwebui.enabled=true \
                --set prometheus.enabled=true \
                --force \
                --wait=false
            }
          fi
          
          # Wait for PVCs to be created and bound
          echo "[$(date)] Waiting for PVCs to be created and bound..."
          MAX_PVC_WAIT=60
          PVC_WAIT_COUNT=0
          while [ $PVC_WAIT_COUNT -lt $MAX_PVC_WAIT ]; do
            PVC_COUNT=$(kubectl get pvc -n triton-inference --no-headers 2>/dev/null | wc -l || echo "0")
            if [ "$PVC_COUNT" -gt 0 ]; then
              BOUND_COUNT=$(kubectl get pvc -n triton-inference -o jsonpath='{.items[*].status.phase}' 2>/dev/null | grep -o Bound | wc -l || echo "0")
              if [ "$BOUND_COUNT" -eq "$PVC_COUNT" ]; then
                echo "[$(date)] âœ“ All PVCs are bound"
                break
              fi
            fi
            PVC_WAIT_COUNT=$((PVC_WAIT_COUNT + 1))
            if [ $PVC_WAIT_COUNT -lt $MAX_PVC_WAIT ]; then
              echo "[$(date)] Waiting for PVCs... ($PVC_WAIT_COUNT/$MAX_PVC_WAIT)"
              sleep 2
            fi
          done
          
          kubectl get pvc -n triton-inference || echo "âš  Some PVCs may not exist yet"
          
          # Now upgrade with wait to ensure deployments are ready
          echo "[$(date)] Upgrading with wait to ensure deployments are ready..."
          if [ "$NAMESPACE_EXISTS" = "false" ]; then
            helm upgrade --install qwen3-8b-triton ./helm/qwen3-8b-triton \
              --namespace triton-inference \
              --create-namespace \
              --timeout 10m \
              --set triton.enabled=true \
              --set openwebui.enabled=true \
              --set prometheus.enabled=true \
              --wait \
              --timeout 10m || echo "âš  Helm wait had issues, but resources may still be deploying..."
          else
            helm upgrade --install qwen3-8b-triton ./helm/qwen3-8b-triton \
              --namespace triton-inference \
              --timeout 10m \
              --set triton.enabled=true \
              --set openwebui.enabled=true \
              --set prometheus.enabled=true \
              --set namespace.create=false \
              --wait \
              --timeout 10m || echo "âš  Helm wait had issues, but resources may still be deploying..."
          fi
          
          echo "[$(date)] Checking deployment status..."
          kubectl get deployments -n triton-inference || true
          echo "[$(date)] Helm deployment completed"

      - name: Verify deployment status
        run: |
          echo "[$(date)] Verifying deployment status..."
          kubectl get deployments -n triton-inference
          kubectl get pods -n triton-inference
          echo "[$(date)] Deployment verification completed"

      - name: Get service endpoints
        id: get-endpoints
        run: |
          echo "=========================================="
          echo "[$(date)] Getting service endpoints..."
          echo "=========================================="
          sleep 15  # Wait longer for LoadBalancer IPs to be assigned
          
          # Retry logic for getting IPs
          MAX_RETRIES=12
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            TRITON_IP=$(kubectl get service triton-qwen3-8b -n triton-inference -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
            OPENWEBUI_IP=$(kubectl get service openwebui -n triton-inference -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
            PROMETHEUS_IP=$(kubectl get service prometheus -n triton-inference -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
            
            if [ -n "$TRITON_IP" ] && [ -n "$OPENWEBUI_IP" ] && [ -n "$PROMETHEUS_IP" ]; then
              break
            fi
            
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "[$(date)] Waiting for LoadBalancer IPs... (attempt $RETRY_COUNT/$MAX_RETRIES)"
            sleep 10
          done
          
          # Set defaults if still empty
          TRITON_IP=${TRITON_IP:-"pending"}
          OPENWEBUI_IP=${OPENWEBUI_IP:-"pending"}
          PROMETHEUS_IP=${PROMETHEUS_IP:-"pending"}
          
          echo "triton_ip=$TRITON_IP" >> $GITHUB_OUTPUT
          echo "openwebui_ip=$OPENWEBUI_IP" >> $GITHUB_OUTPUT
          echo "prometheus_ip=$PROMETHEUS_IP" >> $GITHUB_OUTPUT
          
          echo ""
          echo "=========================================="
          echo "SERVICE ENDPOINTS"
          echo "=========================================="
          echo ""
          echo "Triton Inference Server:"
          echo "  HTTP:    http://$TRITON_IP:8000"
          echo "  gRPC:    $TRITON_IP:8001"
          echo "  Metrics: http://$TRITON_IP:8002/metrics"
          echo ""
          echo "OpenWebUI:"
          echo "  Web UI:  http://$OPENWEBUI_IP"
          echo ""
          echo "Prometheus:"
          echo "  Metrics UI: http://$PROMETHEUS_IP:9090"
          echo ""
          echo "=========================================="

      - name: Get pod and service status
        run: |
          echo ""
          echo "=========================================="
          echo "[$(date)] Pod Status"
          echo "=========================================="
          kubectl get pods -n triton-inference
          echo ""
          echo "=========================================="
          echo "[$(date)] Service Status"
          echo "=========================================="
          kubectl get svc -n triton-inference
          echo ""
          echo "=========================================="
          echo "[$(date)] Ingress Status (if deployed)"
          echo "=========================================="
          kubectl get ingress -n triton-inference 2>/dev/null || echo "No ingress resources found"

      - name: Create Summary
        run: |
          echo "## ðŸš€ Kubernetes Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Cluster:** ${{ env.CLUSTER_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "**Namespace:** triton-inference" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“ Service Endpoints" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Triton Inference Server" >> $GITHUB_STEP_SUMMARY
          echo "- **HTTP:** \`http://${{ steps.get-endpoints.outputs.triton_ip }}:8000\`" >> $GITHUB_STEP_SUMMARY
          echo "- **gRPC:** \`${{ steps.get-endpoints.outputs.triton_ip }}:8001\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Metrics:** \`http://${{ steps.get-endpoints.outputs.triton_ip }}:8002/metrics\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### OpenWebUI" >> $GITHUB_STEP_SUMMARY
          echo "- **Web UI:** \`http://${{ steps.get-endpoints.outputs.openwebui_ip }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Prometheus" >> $GITHUB_STEP_SUMMARY
          echo "- **Metrics UI:** \`http://${{ steps.get-endpoints.outputs.prometheus_ip }}:9090\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "1. Upload model files to PVC (see helm/qwen3-8b-triton/README.md)" >> $GITHUB_STEP_SUMMARY
          echo "2. Test inference endpoint" >> $GITHUB_STEP_SUMMARY
          echo "3. Access OpenWebUI to interact with the model" >> $GITHUB_STEP_SUMMARY
          echo "4. View metrics in Prometheus" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Helm Commands" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
          echo "# Upgrade deployment" >> $GITHUB_STEP_SUMMARY
          echo "helm upgrade qwen3-8b-triton ./helm/qwen3-8b-triton -n triton-inference" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# View values" >> $GITHUB_STEP_SUMMARY
          echo "helm get values qwen3-8b-triton -n triton-inference" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "# Uninstall" >> $GITHUB_STEP_SUMMARY
          echo "helm uninstall qwen3-8b-triton -n triton-inference" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  undeploy:
    name: Undeploy from Kubernetes
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'undeploy'
    environment:
      name: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install jq
        run: |
          echo "[$(date)] Installing jq..."
          sudo apt-get update && sudo apt-get install -y jq
          echo "[$(date)] jq installed"

      - name: Install gke-gcloud-auth-plugin
        run: |
          echo "[$(date)] Installing gke-gcloud-auth-plugin..."
          # Install the plugin component
          gcloud components install gke-gcloud-auth-plugin --quiet 2>&1 || {
            echo "[$(date)] Standard install failed, trying alternative..."
            # Alternative: Use apt-get if available
            sudo apt-get update && sudo apt-get install -y google-cloud-sdk-gke-gcloud-auth-plugin 2>&1 || {
              echo "[$(date)] Apt-get install failed, will use gcloud auth method"
            }
          }
          # Verify installation
          if command -v gke-gcloud-auth-plugin &> /dev/null; then
            echo "[$(date)] âœ“ gke-gcloud-auth-plugin installed successfully"
          else
            echo "[$(date)] âš  gke-gcloud-auth-plugin not found in PATH, but continuing..."
          fi
          # Set environment variable for kubectl
          echo "USE_GKE_GCLOUD_AUTH_PLUGIN=True" >> $GITHUB_ENV
          echo "[$(date)] gke-gcloud-auth-plugin installation completed"

      - name: Configure kubectl
        env:
          USE_GKE_GCLOUD_AUTH_PLUGIN: True
        run: |
          echo "[$(date)] Configuring kubectl for GKE cluster..."
          gcloud container clusters get-credentials \
            ${{ env.CLUSTER_NAME }} \
            --zone ${{ env.GOOGLE_ZONE }} \
            --project ${{ secrets.GCP_PROJECT_ID }}

      - name: Install Helm
        run: |
          echo "[$(date)] Installing Helm..."
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version
          echo "[$(date)] Helm installed"

      - name: Undeploy with Helm
        run: |
          echo "[$(date)] Undeploying with Helm..."
          helm uninstall qwen3-8b-triton --namespace triton-inference || echo "âš  Release not found, may already be deleted"
          echo "[$(date)] Helm undeployment completed"
          
          # Wait a bit for Helm to clean up resources
          echo "[$(date)] Waiting for Helm cleanup..."
          sleep 5
          
          # Force delete any remaining resources that might block namespace deletion
          echo "[$(date)] Cleaning up any remaining resources..."
          
          # Delete PVCs (they might have finalizers)
          kubectl delete pvc --all -n triton-inference --timeout=30s --force --grace-period=0 2>/dev/null || true
          
          # Delete any remaining pods
          kubectl delete pods --all -n triton-inference --timeout=30s --force --grace-period=0 2>/dev/null || true
          
          # Delete any remaining services
          kubectl delete svc --all -n triton-inference --timeout=30s --force --grace-period=0 2>/dev/null || true
          
          # Delete any remaining deployments
          kubectl delete deployments --all -n triton-inference --timeout=30s --force --grace-period=0 2>/dev/null || true
          
          # Remove finalizers from PVCs that might be stuck
          echo "[$(date)] Removing finalizers from stuck resources..."
          for pvc in $(kubectl get pvc -n triton-inference -o name 2>/dev/null); do
            kubectl patch $pvc -n triton-inference -p '{"metadata":{"finalizers":[]}}' --type=merge 2>/dev/null || true
          done
          
          # Remove finalizers from any remaining resources
          for resource in $(kubectl api-resources --verbs=delete -o name | grep -v events); do
            for item in $(kubectl get $resource -n triton-inference -o name 2>/dev/null); do
              kubectl patch $item -n triton-inference -p '{"metadata":{"finalizers":[]}}' --type=merge 2>/dev/null || true
            done
          done
          
          # Delete namespace
          echo "[$(date)] Deleting namespace..."
          if kubectl get namespace triton-inference 2>/dev/null; then
            # Try normal deletion first
            kubectl delete namespace triton-inference --timeout=60s 2>/dev/null || {
              echo "[$(date)] Normal deletion timed out, attempting force deletion..."
              # Remove finalizer from namespace itself
              NAMESPACE_JSON=$(kubectl get namespace triton-inference -o json 2>/dev/null)
              if [ -n "$NAMESPACE_JSON" ]; then
                echo "$NAMESPACE_JSON" | jq '.spec.finalizers = []' | \
                  kubectl replace --raw /api/v1/namespaces/triton-inference/finalize -f - 2>/dev/null || \
                  echo "âš  Could not remove namespace finalizers"
              fi
              
              # Wait a bit and check
              sleep 5
              if kubectl get namespace triton-inference 2>/dev/null; then
                echo "âš  Namespace still exists but should be deleted soon"
                echo "âš  If it remains stuck, manually delete it from GCP Console"
              else
                echo "[$(date)] âœ“ Namespace deleted successfully"
              fi
            }
          else
            echo "[$(date)] Namespace already deleted"
          fi
          
          echo "[$(date)] Undeployment completed"

      - name: Create Summary
        run: |
          echo "## ðŸ—‘ï¸ Kubernetes Resources Removed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All Triton resources have been removed from the cluster." >> $GITHUB_STEP_SUMMARY

